---
title: "SOC-GA 2332 Intro to Stats Lab 3"
author: "Di Zhou"
date: "2/19/2021"
output:
  html_document:
    df_print: paged
    theme: paper
    highlight: textmate
    toc: true
  pdf_document: 
    toc: true
---


<style type="text/css">

body{ 

    font-size: 16px;
    line-height: 1.7em;
    <!-- text-align: justify; -->

}

blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 16px;
    border: solid 1px;
}

h1 { font-size: 32px; }

h2 { font-size: 24px; }

h3 { font-size: 20px; }

</style>

<br>

---

## Logistics & Announcement

- **Problem Set 1** is due on Sat. Feb. 27th, 11:59 pm. -Questions or comments about the assignment? Is the workload okay? 
- You are encouraged to work out these problems as teams (just make sure the submitted document is written on your own). I also understand that it's difficult to do teamwork these days. Just try your best to communicate with your classmates and contact me if you are stuck. 
- Make sure to comment on your code. You will get credit for demonstrating your thought process even if you don't get the final answer correct. 
- If you have questions, please contact me in advance. Don't wait until the last minute! 
- **Rethinking our lab format:** Instead of lecturing, I will allocate more time for you to do coding exercises. For each question, we can have one student sharing her/his screen and go through the code together. The goal is to provide chances for supervised coding experience, so no pressure if you cannot work out the answer. 

---

First, load packages to your environment: 

```{r setup, include = T, message = F, warning = F}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Part 1: Review Simulation

### Simulate the sampling distribution in R   

##### 1. First, create a virtual population

```{r population, warning = F, message = F}    
# Set seed to ensure your code is reproducible. the integer inside doesn't matter, as long as its an integer
set.seed(11011)
# Generate a random number that follows a Bernoulli distribution with p = 0.5
# then covert the vector to a data frame
pop_binom <- rbinom(n = 100000, size = 1, 0.5) %>% as_tibble()

# FOR PSET 1, change "size" to "mean" and add std deviation
# as_tibble changes from vector to data frame

# Check the population distribution
pop_binom %>%
  ggplot(aes(value)) +
  geom_histogram(color = "black", fill = "grey") +
  labs(title = "Histogram of Simulated Population with Bernoulli Distribution",
       subtitle = "N = 100000, p = 0.5",
       x = "")
```
    
##### 2. Second, use a `for`-loop to repeatly sample from the population and save the mean of each sample in a vector. Let's try getting 100 samples with each sample n = 50.  

```{r for-loop, warning = F}
# We create a "container" object to save the result
# It can be a vector, a matrix, a list, etc. as long as it fits your purpose
mean_container <- vector(mode = "numeric", length = 100)

# For-loop
set.seed(10010)
for (i in 1:100){
  # Inside the for-loop, you first randomly sample 50 rows from the pop
  sample <- pop_binom %>% sample_n(size = 50, replace = FALSE)
  # Calculat the mean and save it as the i-th number in the vector
  mean_container[i] <- mean(sample$value)
}

# Chek the result
head(mean_container, n = 10)

```

```{r plot sampling dist, warning = F}

# Mean and SD of the sampling distribution
mean = mean(mean_container)
sd_pos = mean + sd(mean_container)
sd_neg = mean - sd(mean_container)

# Plot
mean_container %>% 
  as_tibble() %>%
  ggplot(aes(value)) +
  geom_histogram(binwidth = 0.01, fill = "grey", color = "black") +
  geom_vline(aes(xintercept = sd_neg), color = "red") +
  geom_vline(aes(xintercept = mean), color = "red", linetype = "dashed") +
  geom_vline(aes(xintercept = sd_pos), color = "red") +
  scale_x_continuous(limits=c(0, 1)) +
  labs(title = "Sampling Distribution of the Sample Mean (100 iterations of sample n = 50)",
       subtitle = "Mean marked by the dashed line, 1 standard deviation around the mean marked by solid lines")

```

---

### Part 1 Exercise  

Create a sampling distribution of the sample mean  
  (1) Create a virtual population that follows a normal distribution of mean = 0 and variance = 1, with 10,000 observations. *Hint*: use `rnorm()`.  
  (2) Use this population and a `for`-loop, get a sampling distribution of the sample mean by sampling 100 observations from the population for 1,000 times.  
  (3) Plot a histogram of your sampling distribution of the sample mean. You can add lines for mean and SD as demonstrated in the figure above.  

*Note:* Use the `set.seed()` function every time you perform a random process. That is, add the `set.seed()` function before every part of your code that involves a random process and run the `set.seed()` function together with that code for every run.     
    
```{r part1-exercise}
set.seed(10101)
pop_ex1 <- rnorm(n = 100000, mean=0, sd=1) %>% as_tibble()

mean_container_ex1 <- vector(mode = "numeric", length = 1000)

set.seed(10001)
for (i in 1:1000){
  sample_ex1 <- pop_ex1 %>% sample_n(size = 100, replace = FALSE)
  mean_container_ex1[i] <- mean(sample_ex1$value)
}

head(mean_container_ex1, n = 10)

# Mean and SD of the sampling distribution
mean_ex1 <- mean(mean_container_ex1)
sd_pos_ex1 <- mean_ex1 + sd(mean_container_ex1)
sd_neg_ex1 <- mean_ex1 - sd(mean_container_ex1)

mean_container_ex1 %>% 
  as_tibble() %>%
  ggplot(aes(value)) +
  geom_histogram(binwidth = 0.01, fill = "grey", color = "black") +
  #geom_vline(aes(xintercept = sd_neg_ex1), color = "red") +
  #geom_vline(aes(xintercept = mean_ex1), color = "red", linetype = "dashed") +
  #geom_vline(aes(xintercept = sd_pos_ex1), color = "red") +
  labs(title = "Sampling Distribution of the Sample Mean (1000 iterations of sample n = 100)", 
       subtitle = "Mean marked by the dashed line, 1 standard deviation around the mean marked by solid lines")
```

---

## Part 2: Hypothesis and Significance Test

First, let's review the standard steps for conducting a significance test:

### 2.1 The standard procedure of a significance test

##### 1. Formulate our research question in the null and alternative hypotheses 

##### 2. Select a significance level ($\alpha$) (in social science, usually $\alpha = 0.05$)

##### 3. Select which test statistics to use (for **population mean**, we use the ***t* test statistics**)

##### 4. If you are collecting first-hand data, select a sample size that provides you with sufficient statistical power (see Agresti textbook 6.6)

##### 5. Derive the **sampling distribution of the test statistic** under the assumption that **the null hypothesis is true** 
* For the *t* test statistics, its sampling distribution is approximately the Student *t* distribution with nâˆ’1 degrees of freedom  
* When n gets larger (usually n > 30), the *t* distribution is approximately a standard normal distribution (see graph below)  
* The *t* test statistic formula is: $t = \frac{\overline y - \mu_0}{se}$ ($\mu_0$ is the population mean in the null hypothesis)  

<p align="center">
![](graph/t_dist.png){width=50%}
</p>  

##### **6a. Derive the critical value of *t* and your rejection region according to the null hypothesis**
* The critical value of *t* is the value beyond which we will regard our observed *t* as "unusual"

* The rejection region will be $(-\infty, -\text{|critical_t|}) \cup (\text{|critical_t|}, \infty)$.

* For samples with a $df \geq 100$, the critical value of *t* is **1.96** for a significance level at 0.05. The rejection region is  $(-\infty, -1.96) \cup (1.96, \infty)$

* For samples with a $df \leq 100$, you can use the "t Distribution Critical Values" table in your textbook to find out the critical value and rejection region:   

  + For a **two-tailed test** that have a significance level at 0.05, we find values from the **$t_{.025}$** column  
  
  + For a **one-tailed test** that have a significance level at 0.05, we find values from the **$t_{.050}$** column 

* You can also use the `qt()` function in R to find out the critical value:  

  + To find out critical value of t for a **two-tailed test**, use `qt(p = 0.5*your_alpha, df = your_degree_of_freedom)`  
  
  + To find out critical value of t for a **one-tailed test**, use `qt(p = your_alpha, df = your_degree_of_freedom)`  
  
  + *Note*: the `qt()` function is the quantile function for the Student t distribution in base R that gives the t value based on the percentile you input  
  
  
<p align="center">
![](graph/agresti_5.5.png){width=70%}
</p>  

##### **6b. Alternatively, you can calculate the P-value of your observed *t* statistic**
* P-value is the probability that the test statistic equals to (or is more extreme than) what we observed  

  + To find out the **two-tail P-value**, use `2*(1 - pt(q = observed_t, df = your_degree_of_freedom))`  
  
  + To find out the **one-tail P-value**, use `1 - pt(q = observed_t, df = your_degree_of_freedom)`  
  
  + *Note*: the `pt()` function is the probability distribution function for the Student t distribution in base R that gives the probability of having a *t* value *smaller* than what you input 
  
<p align="center">
![](graph/agresti_6.3.png){width=70%}
</p>  
        
<p align="center">
![](graph/agresti_6.4.png){width=70%}
</p>  
  

##### 7. Make a conclusion about whether to reject the null hypothesis  
  
  
> You can use this [online tool](https://www.geogebra.org/m/b85v7zww) to visualize a t-test  


--- 

### Part 2.1 Exercise

With $\mu_0 = 0$, $\overline y = 1.54$, sample $n = 27$, $s = 3.25$, derive:  
  (1) The *t* test statistic  
  (2) The critical value of *t* given $H_0$ is true  
  (3) Your rejection region  
  (4) P-value  
  (5) Your conclusion of the significance test  
  
```{r part2.1-exercise}  
t <- ((1.54-0)/3.25)*sqrt(27)
t

# critical value of t from table = 2.056
# qt(p = 0.5*your_alpha, df = your_degree_of_freedom)
crit_t <- qt(p = 0.5*0.05, df = 26)
crit_t

# rejection region = (-infinity, -2.055529) | (2.055529, infinity)

# p-value
# 2*(1 - pt(q = observed_t, df = your_degree_of_freedom))
p <- 2*(1 - pt(q = t, df = 26))
p

# conclusion = reject the null because t is in the rejection region, and because p-value is below 0.05

# note: standard error is the std deviation of the sampling distribution of the sample mean. 
# standard error is NOT the same as the standard deviation
# std deviation is usually of the sample itself
```   

```{r part2-extra-exercise}  
sample_ex <- rnorm(n=30, mean=2, sd=1)

sd_ex <- function(x){
  mean = sum(x)/length(x)
  variance = sum((x-mean)^2)/(length(x)-1)
  std_dev = sqrt(variance)
  return (std_dev)
}

sd_ex(sample_ex)
sd(sample_ex)

```   

> **Notations & Formulas**  
 Sample mean: $\overline y = \frac{y_1 + y_2 + y+3 + ... + y_n}{n}$  
 Sample standard deviation: $s = \sqrt{s^2} = \sqrt{\frac{\sum_{i=1}^n(y_i-\overline y)^2}{n-1}}$  
 Standard error of sample mean: $se = \frac{s}{\sqrt{n}}$  
 Degree of freedom (for estimate one sample population mean): $df = n - 1$ ($n$ is sample size)  
 95% Conf. interval of sample mean: $\hat \mu \pm t_{0.025, df} \cdot se$  
 *t* test statistics: $t = \frac{\overline y - \mu_0}{se}$ ($\mu_0$ is the population mean in the null hypothesis)  
   
   
*Review concepts: What's the difference between **standard error** ($se$) and **standard deviation** ($SD$, or $s$ for sample, $\sigma$ for population)?*  
  
*Review how to hand-code equations in R...(e.g.hand-code a function of sample mean and variance)*

---

### 2.2 One-sample t-test using R

* R provides a simple function `t.test()` to perform hypothesis testing using the *t* test statistics 
* For example, we have data on the weight change of anorexic patients who went through therapy programs,and we want to know whether these therapies are effective (see Agresti textbook example 6.4) 
* We test: $H_0: \mu_{\text{change}} = 0$ (the mean weight change is 0) against $H_{\text{a1}}: \mu_{\text{change}} \neq 0$ (the mean weight change is not 0, a two-tailed test) and $H_{\text{a2}}: \mu_{\text{change}} > 0$ (the mean weight change is larger than 0, a one-tailed test) using the following code:

```{r hypothesis testing using R}

# Import data
weight_df <- read.csv("data/weight.csv")

# Mean of weight change
mean(weight_df$change)


# ---- One sample two-tail t-test ---- 
two_tail_t <- t.test(         
  weight_df$change,           # the sample value vector that you want to test
  mu = 0,                     # mean given by your null hypothesis
  alternative = "two.sided",  # direction of alternative hypothesis
  conf.level = 0.95           # significance level, 1 - alpha
  )

## Extract test statistic
two_tail_t$statistic

## Extract p-value
two_tail_t$p.value

## Extract the confidence interval of the mean
two_tail_t$conf.int

## Display full result
two_tail_t


# ---- One sample one-tail t-test ---- 
t.test(weight_df$change, mu = 0, alternative = "greater", conf.level = 0.95)
# reject the null because p-value is smaller than alpha, in this case smaller than 0.05
```

---

### Part 2.2 Exercise

The institution that offers therapy programs to the anorexic patients claims that their treatment will lead to a weight increase of 4 lbs. Use the `weight_df` data and with $\alpha = 0.05$, perform both a two-tailed and a one-tailed test:
  $$H_0: \mu_{\text{change}} = 4$$
<p align="center">
against
</p>   
  
  $$H_{\text{a1}}: \mu_{\text{change}} \neq 4 \text{   and    } H_{\text{a2}}: \mu_{\text{change}} < 4 $$  
Report your hypothesis testing result. *Hint:* Make sure you put correct arguments for your `t.test()` function! (Are you testing for "two.sided", "less", or "greater"? What's your `mu`?) 

```{r part2.2-exercise}
# check if weight gain is not equal to 4
t.test(weight_df$change, mu = 4, alternative = "two.sided", conf.level = 0.95)
# do not reject the null

# check if weight gain is less than 4
t.test(weight_df$change, mu = 4, alternative = "less", conf.level = 0.95)
# do not reject the null
```

---


## Part 3: Comparing the Mean of Two Groups (Two-sample t-test)

### 3.1 Two independent samples

In the case of comparing the mean of two independent samples, we follow the same procedures as the one sample t-test, except the maths for finding the *t* test statistics change. We will not review all the formulas here. Please review lecture slides and the textbook. 

Using R, we can perform a two-sample t-test by using the same `t.test()` function but adding a second sample mean vector. 

For example, in treating anorexic patients, three different therapies are used. We can plot a boxplot to visualize how weight changes differ across these therapies.
```{r box plot}
# Box plot
weight_df %>%
  ggplot(aes(x = therapy, y = change)) +
  geom_boxplot() +
  geom_point(shape = 1, alpha = 0.7) +
  labs(title = "Weight Changes by Therapy",
       y = "weight change")

```

It looks like therapy f tends to result in a higher weight increase compared to other therapies. Let's use a two-sample t-test to see if the mean weight change in therapy f is statisitcally different from that in therapy c:

$$H_0: \mu_f - \mu_c = 0$$ 
<p align="center">
against
</p>  

$$H_{a}:\mu_f - \mu_c \ne 0$$

```{r two-group-indep}
# Filter data for each therapy
weight_f <- weight_df %>% filter(therapy == "f")
weight_c <- weight_df %>% filter(therapy == "c")

# ---- Two-group independent two-tailed t-test ---- 
t.test(
  x = weight_f$change,          # mean value vector from the first sample
  y = weight_c$change,          # mean value vector from the second sample
  mu = 0,                       # mean difference given by your null hypothesis
  alternative = "two.sided"     # direction of alternative hypothesis
)

#reject the null because p < 0.05. so the mean weight change in therapy f is sig diff from therapy c
```

*Note:* The degrees of freedom of the t-distribution will be $n_0 + n_1 - 2$ **if the population variance of the two groups is equal**. This is often not a very realistic scenario. Out of this reason the Welch's approximation (which we will not define here, but can be found [here](https://en.wikipedia.org/wiki/Welch%27s_t-test) if you are curious) is often used for the degrees of freedom of the $t$ distribution. This is, in fact, the default option in the `t.test()` function that we use in R.

### 3.2 Two dependent samples

In fact, our example in the one-sample t-test in Part 2 is a two dependent sample t-test. For two dependent sample t-test, you can always create a new variable equal to the difference between the two dependent samples, like what we did in Part 2; or you can use the `t.test()` function and set the argument `paired = TRUE`.

For example, in the `weight_df` data, if we want to test weither the mean weight before the treatment is different from the mean weight after the treatment:
$$H_0: \mu_{\text{before}} - \mu_{\text{after}}  = 0$$ 
<p align="center">
against
</p>  
$$H_{a}: \mu_{\text{before}} - \mu_{\text{after}} \ne 0$$

```{r two-group-dep}
# ---- Two-group dependent two-tailed t-test ---- 
t.test(         
  x = weight_df$before,       # mean value vector from the first sample
  y = weight_df$after,        # mean value vector from the second sample
  mu = 0,                     # mean difference given by your null hypothesis
  paired = TRUE,              # dependent samples
  alternative = "two.sided",  # direction of alternative hypothesis
  conf.level = 0.95           # significance level
  )

```

---

### Part 3 Exercise  

Perform a two-sample two-tailed t-test for the difference between therapy b and c:

$$H_0: \mu_b - \mu_c = 0$$ 
<p align="center">
against
</p>  
$$H_{a}:\mu_b - \mu_c \ne 0$$

```{r part3-exercise}

# Filter data for each therapy
weight_b <- weight_df %>% filter(therapy == "b")
weight_c <- weight_df %>% filter(therapy == "c")

# two tailed two indep sample t-test
t.test(
  x = weight_b$change,          # mean value vector from the first sample
  y = weight_c$change,          # mean value vector from the second sample
  mu = 0,                       # mean difference given by your null hypothesis
  alternative = "two.sided"     # direction of alternative hypothesis
)

# P-value is larger than 0.05, we do not reject the null
```

  
---


    
    
    
